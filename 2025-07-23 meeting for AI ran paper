2025/07/23-hh.mm
• 錄音: [未在來源中提供錄音連結，請自行填寫]
• 出席者: Justin Aprio Chan (主要發言人), 參與撰寫論文的學生 (您)
• 主題: 論文進度審查與討論 – 特別聚焦於 AI RAN 相關內容、架構、標準化、工具包、技術可行性、使用案例、部署限制與挑戰
• 總結: 本次會議主要討論了 AI RAN 論文的各個章節內容和撰寫指引。會議中審查了論文的結構，強調了引用來源、重述內容、保持論文流程一致性的重要性。重點討論了 AI RAN 論文中應包含的特定主題，如 AI RAM、O-RAN 標準化努力、不同的 AI 工具包（特別是 OAI 和 Nvidia）、技術可行性、潛在應用、以及部署中面臨的挑戰和限制。會議也提到了實驗室內其他學生的研究方向，並規劃了未來的會議與協作方式。
• 討論重點:
    ◦ 論文撰寫與結構指引:
        ▪ 鼓勵尋找多篇相關論文，特別是關於 AI RAM 和 Jinong Choi 的近期發表。
        ▪ 所有陳述都應提供引用，特別是當資訊來自不同來源時（例如 Qualcomm、Ericsson、Nokia 的資訊需單獨引用）。
        ▪ 優先引用期刊論文、技術論文或白皮書，避免僅使用網站資訊，因為網站內容可能隨時更改或消失。
        ▪ 引用內容應重述，而非直接複製貼上；基於理解用自己的話寫出內容，即便初稿不佳也沒關係，之後再潤飾。
        ▪ 確保論文各部分之間具有連貫性與流程，像講故事一樣，具有好的主線。
        ▪ 撰寫時需思考「為什麼要提及此部分」，並找到不同內容之間的相關性，避免突然跳轉主題。
        ▪ 如果修改了論文內容，需標記清楚（例如您的部分使用紫色，Justin 使用藍色，教授使用紅色），以便教授和Justin容易追蹤修改。
        ▪ 某些內容（例如「彌合先進模型與即時性之間的鴻溝」）屬於挑戰部分，應移動到正確的章節。
        ▪ 不應使用 ChatGPT 一次性重述整個論文內容，但可以用來重述小部分。
    ◦ 核心概念與架構:
        ▪ AI RAM 是重要主題，其中挑戰也應涵蓋在 ARM 中。
        ▪ 強調 O-RAN 標準，例如 O1、A1 和 E2 接口。
        ▪ SMO (服務管理與協調器) 被視為 RAN 的大腦，可在其中安裝多個自定義應用程式，如節能應用程式或即時應用程式。
        ▪ 提及新的架構，將 AI 嵌入 SMO 中，形成 AI SMO。
        ▪ 引入新的標準介面，例如 SMEO (服務管理與暴露) 和 Air1 介面，後者用於應用程式間的通訊（例如節能應用程式與流量預測應用程式之間的通訊）。
        ▪ 探討數位分身（Digital Twin）與 AI 的結合，實現即時模擬和在虛擬環境中測試數據。
        ▪ O-RAN 定義了「去中心化且智能的架構」，這屬於標準化的一部分。
        ▪ 討論了從端到端系統架構（無線單元 RU、分散式單元 DU high/low、集中式單元 CU、5G 核心網、以及網際網路）。
    ◦ AI 工具包與開放原始碼專案:
        ▪ 論文應提及 AI 工具包，首先是 O-RAN 的 OAI/ML 訓練模組，因為實驗室是 O-RAN 實驗室。
        ▪ 其次是 Nvidia 的工具包，例如 Omniverse、SH RT 和 Ariel。
        ▪ 鼓勵尋找其他供應商的 AI 工具包（如 Qualcomm），但目前主要還是 Nvidia。
        ▪ 提及其他開放原始碼專案，如 OpenAirInterface (OAI) 和 SRS RAN，它們都有自己的基站組件 (DU/CU)。
        ▪ Microsoft 也有數位分身模擬器，值得關注。
    ◦ 技術可行性:
        ▪ 探討如何利用不同的開源模組（例如 OAI、Nvidia、SRS RAN、Fox）進行組合和整合。
        ▪ 實驗室有自己的模組組合案例，可參考教授的會議投影片。
        ▪ 需要思考如何實現端到端的系統（RU、DU、CU、5G 核心），目前只有 OAI 擁有 CU。
        ▪ 考慮在論文中包含 O-RAN 框架和 OAI 框架的比較表，包括功能性。
    ◦ 使用案例與潛在應用:
        ▪ 指紋識別 (fingerprinting) 是 AI 實作的一個使用案例。
        ▪ 節能應用程式：依據網路流量智慧地開關基站 (gNodeB)。
        ▪ 流量預測應用程式：根據時間、季節等預測網路流量行為。
        ▪ 數位分身與 AI 結合，用於即時模擬和驗證。
        ▪ 提及「生命週期管理」(life cycle management)，即模型需要根據新數據定期更新和重新訓練，以應對網路拓撲、使用者數量、行為模式的變化。
        ▪ 使用案例應與電信網絡相關，例如 Nvidia Omniverse 在愛立信產品中的應用，避免與鐵路系統等無關的例子。
        ▪ 即時 (real-time) 與非即時 (non-real-time) 的區別：即時處理時間在 1 秒以下（如漫遊切換），非即時則超過 1 秒甚至數小時（如節能或用戶移動性偵測）。
    ◦ 部署限制與挑戰:
        ▪ 模型與即時性之間的差距。
        ▪ 硬體成本高昂：例如 A100 和 H100 GPU 的高價格，並建議提及具體美元價格，同時可探討替代方案，如利用 SSD 或大容量 DRAM 來降低成本。
        ▪ 數據獲取困難：由於隱私問題，營運商的真實數據難以取得；只有少數大學（如德國的德勒斯登工業大學）擁有私人 5G 網路可獲取真實數據。因此，實驗室目前從 Wi-Fi 數據中獲取概念驗證。
        ▪ 大規模數據維護與資源需求：收集數年數據需要大量的儲存資源。
        ▪ 數據標註問題：錯誤的 MAC 位址等錯誤數據可能毀壞整個模型。
        ▪ 頻率政策限制：某些國家對研發頻率有限制。
        ▪ 建立端到端系統的挑戰：並非所有大學都能擁有天線等完整系統。
        ▪ 驅動程式問題和 NDA 限制：商業產品與開源產品整合時可能遇到。
        ▪ AI GPU 的高功耗：雖然有節能應用程式，但 AI 自身的大腦功耗也需要考量。
        ▪ 數據收集本身的資源消耗：從網路中收集數據會消耗網路自身的資源，需要謹慎規劃（例如多執行緒爬取、排程）。
        ▪ 模型維護的生命週期管理：確保模型持續更新和注入新鮮數據。
        ▪ 部署 AI 模型所需的最低硬體規格：例如運行大型語言模型 (LLM) R1 的最低要求。
        ▪ 開源與商業產品整合的挑戰：例如，開源領域目前沒有無線電單元 (RA unit) 的開源解決方案，仍需依賴商業產品。
    ◦ 整合策略與示範架構:
        ▪ 如何整合開源和商業產品是論文的一個重點。
        ▪ 討論系統架構如何用於 AI RAN 示範，包括多個 RA 站點、CU、DU、RU、Near-RT RIC (近即時無線電智能控制器) 和 SMO (服務管理與協調器)。
    ◦ 其他研究方向與協作:
        ▪ Justin 的博士研究方向是數位分身與 AI 的整合，尤其關注數據收集的資源消耗挑戰。
        ▪ Mimo 專注於代理式 AI (agentic AI) 和 SMO AI。
        ▪ Johnson 則研究基於大型語言模型 (LLM) 的自動化修改協調。
        ▪ 鼓勵參與實驗室內部的討論、其他學生的口頭答辯（例如週一的二年級答辯），以及與 Triple-I 的每週會議，以了解最新進展和挑戰。
        ▪ 提到了與教授討論某些特定部分的重要性。
        ▪ 討論了如何將會議錄音轉錄為會議記錄（例如提取音訊到筆記本）。
• 行動項目:
    ◦ [ ] 持續尋找相關論文: 特別是 AI RAM、Jinong Choi 的最新發表、東北大學教授 Melody 和法國 Eurecom 教授 M 的論文，以及實驗室去年提交的調查論文。
    ◦ [ ] 深入研究 Jinong Choi 的張貼內容。
    ◦ [ ] 查閱引用較高的調查論文的引文，以追溯原始思想。
    ◦ [ ] 將 SMEO 和 Air1 介面相關內容納入論文，因其為新標準。
    ◦ [ ] 加入 Air1 和 SMO 的研究小組。
    ◦ [ ] 索取並查閱包含公司實作方案的 YouTube 播放列表。
    ◦ [ ] 探索更多使用案例，特別是 AI 與數位分身的結合應用。
    ◦ [ ] 修改論文時，務必以您的標記顏色（紫色）進行標註。
    ◦ [ ] 將適合的內容（例如挑戰相關內容）移動到論文的「挑戰」章節。
    ◦ [ ] 確保論文中所有陳述都有引用，特別是針對不同來源的資訊。
    ◦ [ ] 在論文中引用 AI 工具包供應商，如 Nvidia SDK。
    ◦ [ ] 撰寫內容時，重述從論文中獲取的資訊，避免直接複製貼上。
    ◦ [ ] 確保論文各部分之間邏輯連貫，形成良好的流程。
    ◦ [ ] 在論文中尋找並包含 AI 工具包的資訊，優先介紹 O-RAN OAI/ML 訓練模組，其次是 Nvidia。
    ◦ [ ] 在論文中保持骨幹結構的一致性，將內容與主要思想（如 AI 工具包、技術靈活性、潛在應用、部署限制）對齊。
    ◦ [ ] 將 O-RAN 架構等標準化內容移動到相關章節。
    ◦ [ ] 您的論文部分應專注於 AI 工具包。
    ◦ [ ] 包含開放原始碼專案的資訊，如 Nvidia 工具包、O-RAN 模組、OpenAirInterface、SRS RAN，以及 Microsoft 的相關內容。
    ◦ [ ] 查找 Microsoft 在數位分身模擬器方面的資訊。
    ◦ [ ] 審查並確定哪些使用案例適用於 AI 控制部分。
    ◦ [ ] 向教授索取會議投影片，了解實驗室如何組合整合不同模組。
    ◦ [ ] 重新評估「模型性能」是否適合放在「技術可行性」部分。
    ◦ [ ] 在「技術可行性」部分涵蓋端到端系統的實作（RU、DU、CU、5G 核心、網際網路）。
    ◦ [ ] 考慮新增 O-RAN 框架和 OAI 框架的比較表。
    ◦ [ ] 為數位分身等應用提供與電信網路相關的現實生活案例，避免脫離範圍的例子。
    ◦ [ ] 減少論文內容的重複。
    ◦ [ ] 在部署限制部分納入解決方案，例如使用 SSD/DRAM 作為 A100 GPU 的替代方案。
    ◦ [ ] 在挑戰部分提及 A100 和 H100 GPU 的價格（美元）。
    ◦ [ ] 探討隱私問題作為部署限制的一個方面。
    ◦ [ ] 尋找 Nvidia Omniverse 的最低硬體規格要求，並在論文中提及。
    ◦ [ ] 將當前內容逐步轉移到 GitHub Markdown 的主文件中。
    ◦ [ ] 繼續撰寫論文至第五部分。
    ◦ [ ] 在整合策略部分，討論如何整合開源和商業產品。
    ◦ [ ] 參考 Tomaso 的論文，說明示範架構。
    ◦ [ ] 與實驗室內的其他碩士生和博士生討論實施挑戰。
    ◦ [ ] 週一參加二年級學生的口頭答辯。
    ◦ [ ] 參加實驗室的每週會議。
    ◦ [ ] 向教授詢問 AI 功耗的能源效率問題。
    ◦ [ ] 與 Mimo 和 Johnson 討論他們的研究視角。
    ◦ [ ] 確保下週論文有重大進展。
    ◦ [ ] 下週一、週二或週三安排一次關於論文的專門討論。
    ◦ [ ] 從下週起參加與 Triple-I 的每週會議。
    ◦ [ ] 與教授討論第五章節的 A 和 B 部分。
    ◦ [ ] 獲取 YouTube 頻道的訪問權限，以便上傳會議錄音。
    ◦ [ ] 週五提交進度報告。
    ◦ [ ] 如有問題，隨時與 Justin 進行電話溝通。
這份會議記錄詳細記錄了本次討論的內容和指引，希望能幫助您更好地理解論文的撰寫方向和要求。
